# API Key Router

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Code style: ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![Type checking: mypy](https://img.shields.io/badge/type%20checking-mypy-blue.svg)](https://mypy.readthedocs.io/)

Intelligent API key routing library and proxy service for managing multiple LLM provider API keys with quota awareness, cost optimization, and intelligent routing.

## Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd ApiKeyRouter

# Install dependencies
poetry install

# Set up environment (optional)
cp .env.example .env
# Edit .env with your configuration
```

### Basic Usage

```python
import asyncio
from apikeyrouter import ApiKeyRouter
from apikeyrouter.domain.models.request_intent import RequestIntent, Message
from apikeyrouter.infrastructure.adapters.openai_adapter import OpenAIAdapter

async def main():
    # Initialize router
    router = ApiKeyRouter()
    
    # Register provider and keys
    await router.register_provider("openai", OpenAIAdapter())
    await router.register_key("sk-your-key-1", "openai")
    await router.register_key("sk-your-key-2", "openai")
    
    # Route a request
    intent = RequestIntent(
        model="gpt-4",
        messages=[Message(role="user", content="Hello!")],
        provider_id="openai"
    )
    
    response = await router.route(intent)
    print(f"Response: {response.content}")
    print(f"Key used: {response.key_used}")

if __name__ == "__main__":
    asyncio.run(main())
```

**See [Quick Start Guide](docs/guides/quick-start.md) for more examples.**

## Features

- üîÑ **Intelligent Routing**: Automatically routes requests across multiple API keys based on availability, cost, and reliability
- üìä **Quota Awareness**: Tracks and manages API quotas, rate limits, and usage across providers
- üí∞ **Cost Optimization**: Minimizes costs by selecting the most cost-effective keys while maintaining reliability
- üîå **Provider Agnostic**: Works with OpenAI, Anthropic, Gemini, and other LLM providers
- üöÄ **FastAPI Proxy**: OpenAI-compatible HTTP API for easy integration
- üîí **Secure**: Encrypted key storage and secure state management
- üìà **Observable**: Comprehensive logging, metrics, and tracing
- üê≥ **Docker Ready**: Pre-built Docker images and Docker Compose setup

## Project Structure

This project uses a **monorepo structure** with Poetry workspace to manage the core library and proxy service packages together.

```
apikeyrouter/
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Core library package (apikeyrouter-core)
‚îÇ   ‚îî‚îÄ‚îÄ proxy/             # Proxy service package (apikeyrouter-proxy)
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ pyproject.toml         # Root workspace configuration
‚îî‚îÄ‚îÄ poetry.lock           # Dependency lock file (generated)
```

### Package Overview

- **apikeyrouter-core**: Core library providing intelligent API key routing, quota management, and cost optimization
- **apikeyrouter-proxy**: FastAPI proxy service that exposes the core library via OpenAI-compatible HTTP endpoints

## Prerequisites

- **Python 3.11+**: Required for all packages
- **Poetry 1.7.1+**: Package manager and dependency management
  - Installation: Follow [Poetry installation guide](https://python-poetry.org/docs/#installation)
  - Verify: `poetry --version`
- **Docker & Docker Compose** (optional, for local MongoDB/Redis):
  - Installation: [Docker Desktop](https://www.docker.com/products/docker-desktop) or [Docker Engine](https://docs.docker.com/engine/install/)
  - Verify: `docker --version` and `docker-compose --version`

## Development Setup

### Working with the Monorepo

The Poetry workspace allows you to work with both packages simultaneously:

```bash
# Install all dependencies
poetry install

# Add dependency to core package
poetry add <package> --directory packages/core

# Add dependency to proxy package
poetry add <package> --directory packages/proxy

# Run commands in specific package
poetry run <command> --directory packages/core
```

### Environment Variables

All environment variables are managed through the `.env` file. Docker Compose automatically loads all variables from `.env`.

Copy `.env.example` to `.env` and configure as needed:

- **Required**: `APIKEYROUTER_ENCRYPTION_KEY` (generate with: `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"`)
- **MongoDB**: `MONGODB_URL`, `MONGO_INITDB_DATABASE`
- **Redis**: `REDIS_URL` (uncomment redis service in docker-compose.yml first)
- **Proxy**: `PORT`, `APIKEYROUTER_MANAGEMENT_API_KEY`, `ENABLE_HSTS`, `CORS_ORIGINS`
- **Core Settings**: `APIKEYROUTER_MAX_DECISIONS`, `APIKEYROUTER_LOG_LEVEL`, etc.

See `.env.example` for a complete list of all available environment variables.

**Note:** The library works in-memory by default. MongoDB and Redis are optional for testing persistence backends.

### Docker Compose Services

The project includes a `docker-compose.yml` file for local development with optional persistence backends:

- **MongoDB**: Available on `localhost:27017` (for optional persistent storage)
- **Redis**: Optional, commented out by default (uncomment in `docker-compose.yml` to enable)

**Start services:**
```bash
docker-compose up -d
```

**Stop services:**
```bash
docker-compose down
```

**View logs:**
```bash
docker-compose logs -f
```

### Running the Proxy Service

```bash
cd packages/proxy
poetry run uvicorn apikeyrouter_proxy.main:app --reload
```

## Testing

### Run All Tests

```bash
poetry run pytest
```

### Run Tests for Specific Package

```bash
# Core package tests
poetry run pytest packages/core/tests

# Proxy package tests
poetry run pytest packages/proxy/tests
```

### Run Specific Test Types

```bash
# Unit tests only
poetry run pytest packages/core/tests/unit

# Integration tests only
poetry run pytest packages/core/tests/integration

# Benchmark/performance tests
poetry run pytest packages/core/tests/benchmarks --benchmark-only

# Run tests with specific markers
poetry run pytest -m unit          # Unit tests
poetry run pytest -m integration  # Integration tests
poetry run pytest -m benchmark    # Benchmark tests
```

### Benchmark Tests

Performance benchmarks measure routing decision time, key lookup performance, and quota calculation speed:

```bash
# Run all benchmark tests with performance metrics
poetry run pytest packages/core/tests/benchmarks --benchmark-only

# Run specific benchmark file
poetry run pytest packages/core/tests/benchmarks/benchmark_routing.py --benchmark-only

# Run benchmarks with verbose output
poetry run pytest packages/core/tests/benchmarks --benchmark-only -v

# Compare benchmark results (saves to .benchmarks/)
poetry run pytest packages/core/tests/benchmarks --benchmark-only --benchmark-save=baseline
```

**Performance Targets:**
- Key lookup: p95 < 1ms
- Quota operations: p95 < 5ms
- Routing decisions: p95 < 10ms

### Test Coverage

```bash
# Run tests with coverage report
poetry run pytest --cov=packages/core/apikeyrouter --cov-report=html

# View coverage report
# Open htmlcov/index.html in your browser
```

**Note:** Some integration tests require optional dependencies (e.g., `motor` for MongoDB tests). These tests are automatically skipped if dependencies are not installed.

## Code Quality

The project uses **ruff** for linting and formatting, and **mypy** for type checking. All quality checks run automatically in CI.

### Format Code

```bash
poetry run ruff format .
```

### Lint Code

```bash
poetry run ruff check .
```

### Type Check

```bash
poetry run mypy packages/core packages/proxy
```

### Run All Quality Checks

```bash
poetry run ruff format . && poetry run ruff check . && poetry run mypy packages/core packages/proxy
```

### Pre-commit Hooks (Optional)

Install pre-commit hooks to automatically run quality checks before each commit:

```bash
# Install pre-commit (if not already installed)
poetry add --group dev pre-commit

# Install the git hook scripts
poetry run pre-commit install

# Run hooks manually on all files
poetry run pre-commit run --all-files
```

Pre-commit hooks will automatically:
- Fix trailing whitespace and end-of-file issues
- Format code with ruff
- Check linting with ruff
- Validate YAML, JSON, and TOML files

### Code Style Standards

See [`docs/architecture/coding-standards.md`](docs/architecture/coding-standards.md) for detailed coding standards and conventions.

Key standards:
- **Line Length:** 100 characters
- **Formatter:** ruff (format on save recommended)
- **Type Checking:** mypy with strict mode enabled
- **Import Sorting:** Automatic via ruff

## Documentation

- **[API Reference](packages/core/API_REFERENCE.md)**: Complete API documentation
- **[Workflows](docs/workflow/product-flow.md)**: Product workflows and system flows
- **[Examples](docs/examples/)**: Code examples and usage patterns
- **[Use Cases](docs/use-cases.md)**: Common use cases and examples
- **[Architecture](docs/architecture/)**: System architecture and design decisions
- **[User Guides](docs/guides/)**: Step-by-step guides and tutorials

## Package Details

### Core Package (`packages/core/`)

The core library provides:
- API key management and state tracking
- Quota awareness and capacity management
- Intelligent routing algorithms
- Cost optimization
- Provider adapter interfaces

**Key Dependencies:**
- `pydantic` - Data validation and models
- `httpx` - Async HTTP client
- `structlog` - Structured logging

### Proxy Package (`packages/proxy/`)

The proxy service provides:
- OpenAI-compatible HTTP API endpoints
- Management API for keys, providers, and policies
- FastAPI-based async HTTP server

**Key Dependencies:**
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `apikeyrouter-core` - Core library (local dependency)

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on:

- Code of Conduct
- Development workflow
- Coding standards
- Testing requirements
- Pull request process

### Quick Contribution Guide

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes following our coding standards
4. Write or update tests
5. Commit your changes (`git commit -m 'feat: add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## Security

### Reporting Security Issues

**Please do not report security vulnerabilities through public GitHub issues.**

Instead, please report them via email to [security@example.com] or see [SECURITY.md](SECURITY.md) for details.

### Security Practices

- **Dependency Scanning**: Automated vulnerability scanning runs on every commit
- **Static Analysis**: Bandit scans code for security issues
- **Secret Scanning**: Automated secret scanning prevents accidental commits
- **Dependabot**: Automated security updates for dependencies
- **Security Headers**: All API responses include security headers
- **Encryption**: API keys encrypted at rest using AES-256
- **Input Validation**: All inputs validated to prevent injection attacks
- **Audit Logging**: All security events logged

See [SECURITY.md](SECURITY.md) for detailed security information.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- **Documentation**: Check the [docs](docs/) directory
- **Issues**: [GitHub Issues](https://github.com/your-username/ApiKeyRouter/issues)
- **Security**: See [SECURITY.md](SECURITY.md) for reporting security vulnerabilities

## Acknowledgments

- Built with [FastAPI](https://fastapi.tiangolo.com/)
- Uses [Pydantic](https://docs.pydantic.dev/) for data validation
- Powered by [Poetry](https://python-poetry.org/) for dependency management
